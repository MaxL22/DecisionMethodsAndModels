% !TeX spellcheck = en_US
\chapter{Programming in conditions of risk}
\label{ch:risk}

This models not only includes the possible scenario set $\Omega$, but also a formalization of their probability. For each given solution $x$, the associated impact $f (x, \omega)$ is a \textit{random variable} depending on the scenario $\omega$. 

Exactly as for the impact function $f(x, \omega)$ the values of $\pi (\omega)$ derive from descriptive models (we'll assume they are given). They might be more or less reliable and this should be taken into account.

We assume:
\begin{itemize}
	\item A preference relation $\Pi$ that is a weak order with a known consistent value function $u(f)$ (replaced by a cost $f$)
	
	\item A uncertain environment: $|\Omega| > 1$ with probabilistic information
	
	\item A single decision-maker: $|D|>1 \implies \Pi_d$ reduces to $\Pi$
\end{itemize}

We then assume:
\begin{itemize}
	\item in the discrete case, a function $\pi_\omega$ assigning to each scenario a \textit{probability value}
	$$ \pi: \Omega \rightarrow [0;1] \ \text{ with } \ \sum_{\omega \in \Omega} \pi_\omega = 1 $$
	
	\item in the continuous case, a function $\pi (\omega)$ assigning to each scenario a \textit{probability density} value
	$$ \pi: \Omega \rightarrow \R^+ \ \text{ with } \ \int_{\omega \in \Omega} \pi (\omega) d \omega = 1 $$
\end{itemize}
We'll consider only finite spaces.

The main approaches consist in reducing the problem to the optimization of an auxiliary function $\phi_{\Omega, \pi} (x)$ (to be maximized or minimized), which removes dependency on the scenario $\omega$.

\section{Definitions of probability}
\label{sec:probdef}

Contrary to the impact, probability is a debated concept with definitions obtained from different sources, with different meanings and possibly contradictory.

The \textit{classical} definition indicates as probability the ratio between the number of elementary cases that form a scenario and the total number of possible elementary cases. This definition assumes that there exists a finite number of elementary cases with same probability, and typically is applied to simple examples.
$$ \pi (\omega) = \frac{n (\omega)}{n (\Omega)} $$

Problems
\begin{itemize}
	\item What is an elementary case? 
	
	\item Why are the elementary cases equally likely?
\end{itemize}
\textit{It looks like a circular definition.} This works well when everything is under control, such as for games.

The \textit{frequentist} definition indicates as probability of a scenario the limit to which its relative frequency tends as the number of observations, or experiments, increases. It does not require to identify elementary cases, it allows nonuniform probabilities but it requires a historical set of observations.
$$ \pi (\omega) = \lim_{n \rightarrow + \infty} \frac{n(\omega)}{n} $$
Problems:
\begin{itemize}
	\item The empirical information must be of good quality
	
	\item The quantity of observation must be very large (we're approximating a limit with a finite number)
	
	\item The future behavior must be similar to the past (we're using past data to take decisions for the future)
\end{itemize}

The \textit{subjective} definition indicates as probability of a scenario the price an individual would consider fair to pay in order to receive $1$ if the scenario occurs and $0$ if it does not. This definition is clearly related to decision problems, as it is based on the idea of having gain or not, and is typically used in economics and finance. It provides value that varies from individual to individual.
$$ \pi(\bar \omega) = u(f(\omega))  \ \text{ where } \ f(\omega) = \begin{cases}
	1 & \text{ if } \omega = \bar \omega \\
	0 & \text{ if } \omega \in \Omega \setminus \{\bar \omega\}
\end{cases}$$
It's the result of a gamble, based on economic reasoning, it does not require repeated experiments in identical conditions and it can exploit any kind of information. 

Problem: it depends on the personal subjective opinion of the modeler. \textit{The personal attitudes are no longer limited to the preference}.

The \textit{axiomatic} definition indicates as probability any function that associates values to scenarios respecting the basic axioms of probability theory (Kolmogorov):
\begin{itemize}
	\item Being restricted in $[0,1]$ for all $\omega \in \Omega$
	
	\item Summing to 1 over all $\omega \in \Omega$
	
	\item Being additive over sets of disjoint scenarios
\end{itemize}
The theory that derives from it is perfectly consistent, but the definition does not indicate how to obtain the values in practical applications.

In practice, one adopts frequentist or subjective values (or a mix) on a case-by-case basis and gets prepared to handle estimation errors.

\section{Expected value criterium}
\label{sec:expectedvaluecrit}

\href{https://en.wikipedia.org/wiki/Blaise_Pascal}{\texttt{Blaise Pascal}} proposed the \textbf{expected value criterium}, that sums up the impacts of a solution over all scenarios with the convex combination of impacts with probabilities
$$ \phi_{EV} (x) = E \left[f (x, \omega)\right] = \begin{cases}
	\sum_{\omega \in \Omega} \pi (\omega) f(x, \omega) & \text{ (discrete case)} \\
	\int_{\omega \in \Omega} \pi(\omega) f(x, \omega) d \omega & \text{ (in the continuous case)}
\end{cases} $$

In the finite case, this corresponds to the product of the evaluation matrix $U = \{f (x, \omega)\}$ times the probability vector:
$$ \phi_{EV} (x) = U \cdot \pi $$

It's a "position measure" of the distribution impact values: 
\begin{itemize}
	\item It lies in the range of these values 
	
	\item It tends to lie in the "middle" of this range
	
	\item It's closer to the values with larger probability 
\end{itemize}

Basically, just the expected values, as in weighted probability: the $f(x, \omega)$ considered times the probability of said scenario, summed for all possible scenarios of a solution, for each solution.

\section{Sensitivity analysis in the probability space}
\label{sec:sensanalysisprobspace}

The probabilities of the single scenarios are often obtained by sampling or estimated based on models, \textit{what if they are wrong?} It is often useful, therefore, to evaluate the dependency of the solution suggested by a criterium form the probabilities of the scenarios, in order to understand whether a possible error can imply a wrong decision, and how large would the mistake be. This corresponds to identifying in the probability space the regions in which alternative is optimal. \\

\begin{definition}
	We denote as \textbf{probability space} the region
	$$ \P (\Omega) = \left\{\pi_\omega \in [0;1]^r \mid \sum_{\omega \in \Omega} \pi_\omega = 1,\ \pi_\omega \geq 0, \ \forall \omega \in \Omega \right\} $$
	where $r = |\Omega|$.  \\
\end{definition}

\begin{definition}
	We denote as \textbf{probabilistic support} of a solution $x \in X$ for a given choice criterium the subset $\Omega_x$ of the probability space $\P (\Omega)$ in which $x$ is optimal according to the choice criterium adopted.
	$$ \supp (x) = \left\{\pi \in \P (\Omega) \mid x \in \arg \min_{x' \in X} \phi_{EV} (x') \right\}$$
\end{definition}

If the alternative chosen based on the estimated probabilities $\pi$ is optimal in a wide region around point $\pi$, one can feel rather safe. In the opposite case, one should take into account for further analysis the other solutions nearby, or the estimate of the probabilities should be improved. 

A complete sensitivity analysis partitions $\P (\Omega)$ into the various supports. We consider a simplified analysis: 
\begin{itemize}
	\item One scenario $\bar \omega$ has a very uncertain probability
	
	\item The other scenarios (consequently) have an overall very uncertain probability, but reliable ratios to each other
\end{itemize}

Assume a nominal probability value $\pi^\circ (\omega)$ for each scenario $\omega \in \Omega$ and study the sensitivity variations of $\pi \left(\omega^{(3)}\right) = \alpha$
$$
\begin{array}{c|cccc }
	f(x,\omega) & \omega^{(1)} & \omega^{(2)} & \omega^{(3)} & \omega^{(4)}  \\
	\hline
	x^{(1)} & 1 & 3 & 4 & 6 \\
	x^{(2)} & 2 & 2 & 2 & 4 \\ 
	x^{(3)} & 3 & 2 & 1 & 9 \\
	x^{(4)} & 6 & 6 & 1 & 3 \\
	\hline
	\pi^\circ (\omega) & 0.20 & 0.25 & 0.50 & 0.05
\end{array}
$$

Let use denote: 
\begin{itemize}
	\item $\pi_k^\circ$ the nominal probability $\pi^\circ \left(\omega^{(k)}\right)$
	
	\item $\pi_k$ the unknown real probability $\pi\left(\omega^{(k)}\right)$
	
	\item $\pi_k'$ the conditional probability $\pi\left(\omega^{(k)} \mid \left(\Omega \setminus \left\{\omega^{(3)}\right\}\right)\right)$ (for $k \neq 3$)
\end{itemize}

Setting $\pi_3 = \alpha$, we obtain that
$$ 
\begin{cases}
	\pi_k^\circ = (1 - \pi_3^\circ) \pi_k' & \text{ for } k \neq 3 \\
	\pi_k = (1 - \alpha)\pi_k' & \text{ for } k \neq 3
\end{cases}
\implies \pi_k = \pi_k^\circ \frac{1 - \alpha}{1 - \pi_3^\circ} \ \text{ for } k \neq 3
$$

All probabilities are linear functions in $\alpha$, consequently, also $\phi_{EV} (x)$ is linear in $\alpha$. In the present case, $1 - \pi_3^\circ = (1 - 0.5)$, from which: 
$$
\begin{array}{c | c c c c}
	& \omega^{(1)} & \omega^{(2)} & \omega^{(3)} & \omega^{(4)} \\
	\hline
	\phi_{EV} (x) & (2.5 + 1.5\alpha) & (2.2 - 0.2\alpha) & (3.1 - 2.1\alpha) & (5.7 - 4.7 \alpha)
\end{array}
$$
\begin{center}
	\begin{tikzpicture}
		\begin{axis}[
			xlabel={$\alpha$},
			ylabel={$u$},
			grid=major,
			legend pos=north east,
			domain=0:1,
			samples=100,
			width=10cm,
			height=8cm
			]
			%Functions
			\addplot[red, thick, name path=4] {2.5+1.5*x};
			\addlegendentry{$u(x_1)$}
			\addplot[green, thick, name path=1] {2.2-0.2*x};
			\addlegendentry{$u(x_2)$}
			\addplot[blue, thick, name path=2] {3.1-2.1*x};
			\addlegendentry{$u(x_3)$}
			\addplot[magenta, thick, name path=3] {5.7-4.7*x};
			\addlegendentry{$u(x_4)$}
			\fill (0.47,2.1) circle (2pt) node[below] {$A$};
		\end{axis}
	\end{tikzpicture}
\end{center}

Two solutions have nonempty support (the ones with no other functions below), and the threshold is obtained by intersecting their impact values
$$ 2.2 - 0.2 \alpha = 3.1 - 2.1 \alpha \implies \alpha = \frac{9}{19} $$
So that $\supp\left(x^{(2)}\right) = \left[0, \frac{9}{19}\right]$ and $\supp\left(x^{(3)}\right) = \left[\frac{9}{19}, 1\right]$.

\section{Formal defects of the expected value criterium}
\label{sec:formdefexpectedvalue}

Since the Seventeenth century, the expected value criterium was criticized for the unrealistic consequences (sometimes even paradoxical) it leads to.

Some strong defects of the expected value criterium:
\begin{enumerate}
	\item The actual preferences are inconsistent with the expected values
	
	\item Extreme values of probability and impact have paradoxical effects
\end{enumerate}

\subsection{Inconsistency between expected value and actual preferences}

According to the expected value criterium, all the combinations of impacts and probabilities producing the same result are reciprocally indifferent. In practice, this is often false: if one proposes to a decision-maker different combinations of impacts and probabilities with the same expected value, nearly always the decision maker shows a preference, even if this changes depending on the decision-maker. 

Consider the following alternatives:
\begin{itemize}
	\item Throw a die and gain 100 Euros for all outcomes
	
	\item Throw a die and gain 200 Euros for 4,5 and 6
	
	\item Throw a die and gain 600 Euros for 6
	
	\item Throw a die and gain 200 Euros for 2,3,4,5,6 and -400 Euros for 1
\end{itemize}

All alternatives have equal expected value: $\phi_{EV} (x) = 100$, $\forall x \in X$, most decision-makers however would consider them very different.

\subsection{Infinite expected values and infinitesimal probabilities}

There are thought experiments which show inconsistencies between practical preferences and the expected value criterium when applied to situations in which some impacts are unlimitedly large and some probabilities are unlimitedly small. 

In general, with this method, combining small probabilities with large impacts looks problematic.

\paragraph{Saint Petersburg's Paradox} The situation concerns a gamble:
\begin{itemize}
	\item The gambler pays $P$ to take part to the game
	
	\item We flip a coin until a tail is obtained
	
	\item The gambler wins a sum depending on the number of flips before the end of the game
\end{itemize}

The model of the game is the following;
\begin{itemize}
	\item Alternatives: play or do not play
	
	\item Scenarios: the coin is flipped $k$ times obtaining heads before the first tail ($\Omega = \N$)
	
	\item Probability function: $\pi_k = \frac{1}{2^{k+1}}$
	
	\item Impact function: 
	\begin{itemize}
		\item if we do not play, $f(P, k) = 0$
		
		\item if we do play, $f(P,k) = 2^k - P$
	\end{itemize}
\end{itemize}
\textit{What is the largest $P$  one should be willing to pay to play the game?}

Let's apply the expected value criterium:
\begin{itemize}
	\item If we do not play, $\phi_{EV} (P) = 0$
	
	\item If we do play, $\phi_{EV} (P) = \sum_{k \in \N} \frac{2^k - P}{2^{k+1}} = \sum_{k \in \N} \frac{1}{2} - \sum_{k \in \N} \frac{P}{2^{k+1}} = + \infty$
\end{itemize}

Playing pays out an infinite gain: any cost $P$ is justified. However, in real life nobody would pay a large sum.

\paragraph{A possible way out} Bernouilli suggested not to multiply probabilities and impacts: 
\begin{itemize}
	\item For finite creatures the utility for a gain is not proportional to it
	
	\item The marginal increase in utility is decreasing
\end{itemize}

Bernouilli suggested that \textit{utility increases logarithmically with the gain}
$$ u = \log (f) $$

This solves the original Saint Petersburg's paradox, but not a variant with gains $f$ increasing more than exponentially at each coin flip.

The paradox disappears only when the utility function is upper bounded.

%End L17, p288 notes

\section{Stochastic utility theory}
\label{sec:stochastic}

We aim to overcome the limits of the expected value criterium, by introducing a number of desired properties (axioms) and building a choice criterium that by construction satisfies them. 

We assume:
\begin{itemize}
	\item A preference relation $\Pi$ that is a weak order with a known constant value function $u(f)$ (replaced by a cost $f$)
	
	\item An uncertain environment: $|\Omega| > 1$ with probabilistic information
	
	\item A single decision-maker: $|D| = 1 \implies \Pi_d$ reduces to $\Pi$
\end{itemize}

The basic idea is to assume that the decision-maker is able to establish a preference relation $\Pi$ not only between pairs of deterministic impacts, but also between pairs of uncertain impacts, described as random variables. \\

\begin{definition}
	We denote as \textbf{finite simple lottery} $\ell_{f, \pi}$ a pair of functions $(f(\omega), \pi (\omega))$, where $f(\omega): \Omega \rightarrow F$ is a random variable on a finite sample space $\Omega$, while $\pi (\omega): \Omega \rightarrow [0;1]$ is a probability function on $\Omega$.
\end{definition}

The set of all finite lotteries on $F$ and $\Omega$ is therefore  
$$ \lottset = F^{|\Omega|} \times \P (\Omega) $$
as it contains all pairs of vectors such that the former has $|\Omega|$ components  in $F$ and the latter belongs to the probability space on $\Omega$. 

In a decision problem in conditions of risk, each alternative $x \in X$ corresponds to a lottery $\ell (x) \in L_x \subset L_{f, \Omega}$
$$ x \leftarrow \ell (x) = \left(f(x, \omega_1), \pi (\omega_1)\right) \oplus \dots \oplus \left(f(x, \omega_r), \pi (\omega_r)\right)$$
where we skip the terms of zero probability for the sake of brevity. \textit{This notation is nonstandard}. \\

\begin{definition}
	We denote as \textbf{degenerate lottery} a lottery where a single scenario has probability of 1
	$$ \ell_f = (f, 1) $$
\end{definition}

A single deterministic impact in $F$ is equivalent to a degenerate lottery. \\

\begin{definition}
	We denote as \textbf{binary lottery} a lottery where two scenarios have positive probability
	$$ \ell_{f, \alpha, f'} = (f, \alpha) \oplus (f', 1-\alpha)$$
\end{definition}

The simple lottery set $\lottset$ extends by recursion to lottery with multiple phases, where the impact obtained in each scenario is allowed to be a lottery; only the final phase provides deterministic gains and losses. \\

\begin{definition}
	We denote as \textbf{compound lottery} a lottery whose impacts are other lotteries (possibly degenerate).
\end{definition}

Compound lotteries model
\begin{itemize}
	\item lotteries taken in subsequent phases
	
	\item decisions taken before a sequence of uncertain events
\end{itemize}

They admit a graphical tree representation with:
\begin{itemize}
	\item Uncertain events on the internal nodes
	
	\item Deterministic impacts on the leaves
	
	\item Conditional probabilities on the arcs
	
	\item Probabilities summing to 1 on the arcs going out of each node \\
\end{itemize}

\begin{definition}
	We denote as $\lottset$, the set of all possible lotteries, simple or compound, on $F$ and $\Omega$.
\end{definition}

Given a finite decision problem in condition of risk, for any generic alternative $\bar x \in X$, the impact $f(\bar x, \omega)$ and the probability $\pi$ respect the definition of finite lottery. Therefore, any $x \in X$ corresponds to a lottery $\ell (x) \in \lottset$ and a method allowing to compare lotteries also allows to compare alternatives.

\subsection{Fundamental axioms of stochastic utility}

The stochastic utility theory first defines the properties that a preference relation between lotteries should respect in order to be rational. Then it proves that only a well-determined family of preference relation satisfies such properties, and that such relations can be represented by real-valued consistent functions. In this way, the selection of an alternative (lottery) among the feasible ones is equivalent to the optimization of the consistent function. \\

\begin{definition}
	A \textbf{preference relation between lotteries} is a binary relation on the lottery set
	$$ \Pi  \subset 2^{\lottset \times \lottset} $$
\end{definition}

\begin{definition}
	A preference relation between lotteries $\Pi \subset 2^{\lottset \times \lottset}$ admits a \textbf{consistent stochastic utility function} $u: \lottset \rightarrow \R$ when, for every pair of lotteries $\ell$ and $\ell'$, the utility of the preferred one exceeds the utility of the other one
	$$ \ell \wpref{} \ell' \Leftrightarrow u(\ell) \geq u(\ell') $$
\end{definition}

Von Neumann and Morgenstern
\begin{enumerate}
	\item Assume the existence of a preference relation $\Pi$ on lotteries
	
	\item Impose suitable conditions on $\Pi$
	
	\item Build a stochastic utility function $u(\ell)$ that is consistent with $\Pi$
	
	\item Reduce the decision problem in conditions of risk to
	$$ \max u(\ell (x)) $$
	$$ x \in X \Leftrightarrow \ell (x) \in L_X $$
	where feasible region $X$ corresponds to the feasible lotteries $L_X \subset \lottset$
\end{enumerate}

The properties required from a rational preference between lotteries, or axioms of stochastic utility, are the following: 
\begin{enumerate}
	\item \textbf{Weak ordering:} the preference relation between lotteries $\Pi$ is reflexive, transitive and complete
	
	\item \textbf{Monotony:} lotteries (both simple and compound) that assign larger probabilities to better impacts or lotteries are preferable
	$$ \alpha \geq \beta \Leftrightarrow (\ell, \alpha) \oplus (\ell', 1 - \alpha) \wpref{} (\ell, \beta) \oplus (\ell', 1 - \beta), \quad \forall \ell \wpref{} \ell' $$
	
	\item \textbf{Continuity:} any intermediate impact between two lotteries admits an equivalent compound lottery with the two given ones as outcomes: 
	$$ \ell \wpref{} f \wpref{} \ell' \implies \exists \alpha \in [0;1] : f \sim (\ell, \alpha) \oplus (\ell', 1 - \alpha) $$
	For any intermediate impact between lotteries, there exists a suitable probability value which allows to compose the two given lotteries into a lottery indifferent to the impact. Changing in a continuous way the probabilities modifies the preference continuously, leaving no impact "uncovered".
	
	\item \textbf{Independence} (or \textbf{substitution})\textbf{:} the preference between two lotteries does not change combining them with the same lottery with the same probability:
	$$ \ell \wpref{} \ell' \Leftrightarrow (\ell, \alpha) \oplus (\ell'', 1 - \alpha) \wpref{} (\ell', \alpha) \oplus (\ell'', 1-\alpha), \quad \forall \alpha \in (0;1] $$
	
	\item \textbf{Reduction:} any compound lottery is indifferent to the simple lottery with: 
	\begin{itemize}
		\item the same final impacts
		
		\item probabilities given by the laws of
		\begin{itemize}
			\item conditional probabilities: multiply along each path
			
			\item total probabilities: sum on disjoint path
		\end{itemize}
	\end{itemize}
	Impacts and probabilities are relevant, the lottery structure is not. Basically, we can keep just a simple lottery with all final impacts and probabilities suitably adjusted.
\end{enumerate}

\subsection{Von Neumann-Morgenster stochastic utility theorem}

The following theorem proves that, under the axioms discussed above, it's always possible to build a consistent stochastic utility function to compare lotteries. Moreover, it's possible to build infinitely many such functions, that coincide with one another up to a linear scaling, so that there is one and only one normalized utility function. Since the proof is constructive, it also shows how to build such function. \\

\begin{theo}
	Given a set of impacts $F$ not all reciprocally indifferent, a sample space $\Omega$ and a preference relation $\Pi$ between lotteries on $F$ and $\Omega$ that respects the five axioms of Von Neumann and Morgenstern, there exists one and only one utility function $u (\ell): \lottset \rightarrow [0,1]$ consistent with $\Pi$ and normalized so as to have value 0 in the worst impact and 1 in the best impact.
\end{theo}

\begin{proof}
	The existence of a weak order on $F$ guarantees that there exists at least one worst impact $f^\dag$ and one best impact $f^\circ$ in $F$. Let $\ell^\dag = (f^\dag, 1)$ be the degenerate lottery that certainly returns the worst impact and $\ell^\circ = (f^\circ, 1)$ the degenerate lottery that certainly returns the best impact.  Since all impacts are not reciprocally indifferent
	$$ f^\circ \prec f^\dag \ \text{ that is } \ \ell^\circ \prec \ell^\dag $$
	
	Now we can assign extreme conventional values to the utility of these two lotteries
	$$ u(\ell^\dag) = 0 \ \text{ and } \ u(\ell^\circ) = 1 $$
	
	As a second step, we build the utility values for all degenerate lotteries, that is for all impacts in $F$, exploiting the continuity axiom. For every impact $f \in F$ there exists certainly a probability $\alpha_f \in [0;1]$ that produces a lottery between the two extreme impacts and is indifferent with respect to the degenerate lottery corresponding to $f$: 
	$$ \exists \alpha_f \in [0;1] : (\ell^\circ, \alpha_f) \oplus (\ell^\dag, 1 - \alpha_f) \sim f $$
	
	The value of $\alpha_f$ is unique thanks to the monotony axiom.
	
	As a third step, we build utility values for general lotteries. In order to do that, we exploit the substitution and reduction axioms. Every possible final impact $f \in F$ of a lottery can be seen as a degenerate lottery $\ell_f$, which is equivalent to a binary lottery $(\ell^\circ, \alpha_f) \oplus (\ell^\dag, 1 - \alpha_f)$ between the extreme impacts. Given a general lottery $\ell$ each of its final impacts $f$ can be replaced with the degenerate lottery or with the equivalent binary lottery obtaining a compound two-phase lottery. The first phase no longer provides the single impacts, but tickets to take part to the second phase, in which only extreme impacts $f^\circ$ and $f^\dag$ are possible.
	
	The reduction axiom allows to combine the two phases into a single lottery with the same final impacts (the two extreme ones) and probabilities determined by the theorem of total probability. Now, the given lottery $\ell$ corresponds to a simple lottery between the extreme impacts
	$$ \ell \sim \left(f^\circ, \sum_{\omega \in \Omega} \pi_\omega \alpha_{f(\omega)} \right) \oplus \left(f^\dag, 1 - \sum_{\omega \in \Omega} \pi_\omega \alpha_{f(\omega)}\right) $$
	
	We define the utility lottery $\ell$ as the probability of the best impact $\ell^\circ$. Since $\alpha_f = u(\ell_f)$, the stochastic utility of a lottery coincides with the expected value of the utility of the impact
	$$ u(\ell) = \sum_{\omega \in \Omega} \pi_\omega u(f(\omega)) = E \left[u(f)\right] $$
\end{proof}

The utility of a lottery is the expected value of the utility in the scenarios, \textit{as Bernouilli proposed, combine perceived utilities, not impacts}.

In summary, the Von Neumann-Morgenstern theorem
\begin{itemize}
	\item Receives from the decision-maker $u(f)$ for all $f \in F$
	
	\item Returns $u(\ell)$ for all $\ell \in L$
\end{itemize}

Since in a decision problem an alternative is a lottery, we pick the maximum expected value (benefits).

Stochastic utility and multi-attribute utility exhibit strong similarities:
\begin{itemize}
	\item They are convex combinations of utilities with coefficients
	
	\item The utilities are normalized between a worst and best impact
	
	\item The coefficients are normalized between 0 and 1 with unitary sum
\end{itemize}

But there are also strong differences:
\begin{itemize}
	\item Additivity is intrinsically satisfied (no special condition required) because the different scenarios do not interact, while indicators do
	
	\item The attribute set $P$ is replaced by scenario set $\Omega$, possibly infinite
	
	\item The weights $w_l$ are replaced by probabilities $\pi (\omega)$ that do not necessarily require the decision-maker (they might be frequencies)
\end{itemize}

\section{Risk aversion and risk propensity}
\label{sec:riskaversion}

\begin{definition}
	We denote as \textbf{risk profile} the profile of the stochastic utility function on the degenerate lotteries $\ell_f$ as impact $f$ varies in $F$.
\end{definition}

The shape of $u(f)$ for all $f \in F$, it determines $u(\ell(f, \pi))$ for all $\ell \in L$, combining $u(f)$ and $\pi (\omega)$, therefore \textit{showing the attitude of the decision-maker} towards risk.

For the sake of simplicity, we'll assume that
\begin{itemize}
	\item $f$ is a benefit
	
	\item The impact set is an interval $F = \left[f^\dag, f^\circ\right]$
	
	\item Consequently, the risk profile increases from $(f^\dag, 0)$ to $(f^\circ, 0)$
\end{itemize}

The extension to more general cases is possible.

Now consider: 
\begin{itemize}
	\item An intermediate deterministic impact $f_\alpha = (1 - \alpha) f^\dag + \alpha f^\circ$
	
	\item A binary lottery $\ell_{f^\circ, \alpha, f^\dag}$ combining $f^\circ$ and $f^\dag$ with coefficient $\alpha$
\end{itemize}

They are equivalent for the expected value criterium
$$ \phi_{EV} (f_\alpha) = f_\alpha = \phi_{EV} \left(\ell_{f^\circ, \alpha, f^\dag}\right)$$

\textit{What about their stochastic utilities $u(f_\alpha)$ and $u \left(\ell_{f^\circ, \alpha, f^\dag}\right)$?} The utility of any binary lottery $\ell_{f^{(1)}, \alpha, f^{(2)}}$ can be computed from the segment between points $\left(f^{(1)}, u\left(f^{(1)}\right)\right)$ and  $\left(f^{(2)}, u\left(f^{(2)}\right)\right)$
$$ u \left(\ell_{f^\circ, \alpha, f^\dag}\right) = \alpha u \left(f^\circ\right) + \left(1 - \alpha\right)u \left(f^\dag\right) $$

Three relevant cases (not exhaustive) exist: 
\begin{enumerate}
	\item \textbf{Convex case:} the risk profile is above the segment from $(f^\dag, 0)$ to $(f^\circ, 1)$ and the lottery is preferred to the deterministic impact
	$$ u\left(f_\alpha\right) \leq u \left(\ell_{f^\circ, \alpha, f^\dag}\right), \quad \forall \alpha \in [0,1] $$
	The decision maker is \textit{risk-prone}
	
	\item \textbf{Linear case:} the risk profile is lying on the segment from $(f^\dag, 0)$ to $(f^\circ, 1)$ and the lottery and the deterministic impact are equivalent
	$$ u\left(f_\alpha\right) = u \left(\ell_{f^\circ, \alpha, f^\dag}\right), \quad \forall \alpha \in [0,1] $$
	The decision-maker is \textit{risk-neutral, the expected value criterium is confirmed}
	
	\item \textbf{Concave case:} the risk profile is below the segment from $(f^\dag, 0)$ to $(f^\circ, 1)$ and the deterministic impact is preferred to the lottery 
	$$ u\left(f_\alpha\right) \geq u \left(\ell_{f^\circ, \alpha, f^\dag}\right), \quad \forall \alpha \in [0,1] $$
	The decision-maker is \textit{risk-averse}
\end{enumerate}

\subsection{Certainty equivalent and risk premium}

An equivalent description of the risk profile of a decision-maker is given by the inverse of the utility function, that is the function that rebuilds an impact $f(u)$ for each possible value of the stochastic utility $u$. This inverse function certainly exists, given that $u(f)$ is strictly increasing. \\

\begin{definition}
	Given a lottery $\ell$ we denote as \textbf{certainty equivalent} the deterministic impact $f_\ell$ that is equivalent to the lottery, and \textbf{risk premium} the difference between the expected value of the lottery and its certainty equivalent.
\end{definition}

The certainty equivalent can differ from the expected value of the impact. Given a lottery $\ell$ of utility $u$: 
\begin{itemize}
	\item The expected value of the impact is $\phi_{EV} (\ell) = E \left[f(\ell, \omega)\right]$
	
	\item The certainty equivalent is $CE(\ell) = f(u(\ell))$
\end{itemize}

The risk premium $RP(\ell)$ is the difference of the two terms
$$ RP(\ell) = \phi_{EV} (\ell) - CE(\ell) = E\left[f(\ell, \omega)\right] - f(u(\ell)) $$

The risk premium measures the additional utility that the decision-maker requires in order to accept a lottery instead of its expected value. Therefore: 
\begin{itemize}
	\item For risk-averse decision-makers, the certainty equivalent of a lottery is smaller than its expected value, and the risk premium is positive
	
	\item For risk-neutral decision-makers, the certainty equivalent of a lottery is equal to its expected value, and the risk premium is zero 
	
	\item For risk-prone decision-makers, the certainty equivalent of a lottery is larger than its expected value, and the risk premium is negative
\end{itemize}

%End L18, p299 notes